# Women In Data 2022

## Webscraping and data cleaning project

### Introduction

At the end of this session, you will understand the most important components of web scraping, you will be able to build your own web scrapers to obtain new data, understand some of the most common scraping techniques and sharpen your Python programming skills while youâ€™re at it!

### Requirements

You will need a python3+ virtual environment with the following packages installed:

1. Scrapy
2. Pandas
3. Selenium and its web drivers
4. Spyder
5. Beautifulsoup

### Objectives

- Introduction to web scraping
- Is web scraping legal?
- Explore the framework of a website
- Understand various parsers
- Create scrapy crawlers/spiders
- Scrape data using BeautifulSoup, Scrapy and selenium Applications:
      - Scrape product information
      - Store the data in dataframes and csv
      - Data cleaning

### Project Directions
- clone this project
```
git clone https://github.com/jmugure95/WID-2022.git
```
- create a virtualenv
```
virtualenv -p python3.8 webscrapper
```
- cd into the cloned folder (WID-2022)
```
cd WID-2022
```
- Install the requirements from the requirements
```
pip3 install -r requirements.txt
```

### The above directions are for use on a linux terminal, if using a Mac or Windows, kindly tweak them for your environment